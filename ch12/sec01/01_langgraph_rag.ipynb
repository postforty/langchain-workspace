{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6eaa9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 문서 로드\n",
    "loader = PyMuPDFLoader('../data/KCI_FI003153549.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06dd829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 0}, page_content='JKSCI\\n한국컴퓨터정보학회논문지\\nJournal of The Korea Society of Computer and Information\\nVol. 29 No. 12, pp. 169-180, December 2024\\nhttps://doi.org/10.9708/jksci.2024.29.12.169\\nClinical Trials Utilizing LLM-Based Generative AI\\n1)Hyon-Chel Jung*,  Kun-Soo Shin**,  Ho-Dong Kim***,  Sung-Bin Park****\\n*Research Professor, Dept. of Institute of Artificial Intelligence and Big Data in Medicine, Yonsei University \\nWonju College of Medicine, Korea \\n**Researcher, Dept. of Yonsei University Future Medical Industry Cooperation Group, Korea\\n***Executive Vice President, Head of AI, Corporate Research Institute, Solbit Co., Ltd., Korea\\n****Professor, Dept. of Precision Medicine, Yonsei University Wonju College of Medicine, Korea\\n[Abstract]\\nThis study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and \\nproblems that arise during clinical trial operation. Finally, by evaluating the performance of the system, \\nwe propose a direction to increase the efficiency and reliability of clinical trial operation and medical \\ndevice development. As a result of the study, the Private LLM system has outperformed the existing \\nmethodology in supporting task automation and precise decision making. In particular, the ability to \\nprovide accurate answers to questions from domain experts and to generate new clinical criteria and \\ninsights shows the potential to become an innovative tool in clinical trial operation of medical devices. \\nThis confirmed the practical applicability of Private LLM in precision medical care, automation of \\nclinical trial management, and a Q&A system based on domain knowledge. \\n▸Key words: Large Language Models(LLMs), Generative Al, Clinical Trials, Medical Devices, Data Analysis\\n∙First Author: Hyon-Chel Jung, Corresponding Author: Sung-Bin Park\\n  *Hyon-Chel Jung (bravojhc@yonsei.ac.kr), Dept. of Institute of Artificial Intelligence and Big Data in Medicine, \\nYonsei University Wonju College of Medicine\\n  **Kun-Soo Shin (tlsrjstn788@naver.com), Dept. of Yonsei University Future Medical Industry Cooperation Group\\n  ***Ho-Dong Kim (hodong.kim@solbit.kr), Corporate Research Institute, Solbit Co., Ltd.\\n  ****Sung-Bin Park (sung.b.park@gmail.com), Dept. of Precision Medicine, Yonsei University Wonju College of Medicine\\n∙Received: 2024. 11. 01, Revised: 2024. 12. 02, Accepted: 2024. 12. 18.\\nCopyright ⓒ 2024 The Korea Society of Computer and Information                                               \\n      http://www.ksci.re.kr pISSN:1598-849X | eISSN:2383-9945'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 1}, page_content='170   Journal of The Korea Society of Computer and Information \\n[요   약]\\n본 연구는 대규모 언어 모델(LLM) 기반의 Private LLM을 활용하여 의료기기 임상시험 분야에 \\n적용하여 업무 효율성과 전문성 향상을 탐구한다. Private LLM 시스템은 임상 데이터를 기반으로 \\n정교하고 정확한 답변을 제공하며, 의사결정 지원, 임상 전문가 활동 보조, 새로운 콘텐츠 생성, \\n문제 해결 등 다양한 응용 분야에서 활용 가능성을 보여준다. 연구는 다음 네 가지 주요 단계로 \\n구성된다. 첫째, 의료기기 임상시험에 특화된 데이터를 수집하고 이를 전처리하여 학습 가능한 형\\n식으로 정리한다. 둘째, LLaMA와 같은 오픈소스 LLM 모델을 기반으로 PEFT(LoRA) 및 RAG 기\\n법을 적용하여 특정 임상 도메인에 맞는 맞춤형 Private LLM 질의응답 시스템을 구축한다. 셋째, \\n구축된 시스템을 활용하여 전문가 수준의 질의응답 기능을 실현하고, 임상시험 운영 중 발생하는 \\n복잡한 질문과 문제를 해결한다. 마지막으로, 시스템의 성능을 평가하여 임상시험 운영과 의료기\\n기 개발의 효율성과 신뢰성을 높이기 위한 방향성을 제안한다. 연구 결과, Private LLM 시스템은 \\n기존의 방법론 대비 업무 자동화와 정밀한 의사결정 지원에서 탁월한 성능을 보였다. 특히, 도메\\n인 전문가의 질문에 대한 정확한 답변을 제공하고, 새로운 임상 기준 및 인사이트를 생성할 수 \\n있는 능력은 의료기기 임상시험 운영의 혁신적 도구로 자리잡을 가능성을 보여준다. 이를 통해 \\n정밀 의료, 임상시험 관리 자동화, 그리고 도메인 지식 기반의 질의응답 시스템에서 Private LLM\\n의 실질적 활용 가능성을 확인하였다.\\n▸주제어: 대규모 언어 모델, 생성형 인공지능, 임상시험, 의료기기, 데이터 분석\\nI. Introduction\\n대규모 언어 모델(Large Language Models, LLM)의 \\n발전은 최근 몇 년간 인공지능(AI) 기술의 중요한 진전으\\n로 자리 잡고 있다 [1]. LLM 기반 생성형 AI는 자연어 처\\n리와 텍스트 생성, 데이터 분석 등 다양한 분야에서 뛰어\\n난 성능을 보이고 있으며, 특히 의료기기 임상시험에서 그 \\n효용성이 점점 더 높아지고 있다. 기존의 임상시험 데이터 \\n분석 방식은 대규모 데이터를 처리하는 데 있어 시간적, \\n비용적 한계가 있었고, 이는 임상시험의 신뢰성과 효율성\\n에도 부정적인 영향을 미쳤다.\\nLLM 기반 생성형 AI는 기존 방법의 한계를 해결할 수 있\\n는 도구로 떠오르고 있다 [2]. 이 기술은 방대한 임상 데이터\\n를 분석하고, 그 안에서 중요한 패턴을 신속하게 찾아냄으로\\n써 더 나은 의사결정을 가능하게 한다. 특히 임상시험 과정\\n에서 데이터의 정확한 처리가 이루어져야 하는 만큼, LLM \\n기반 분석은 기존 방식과 비교할 때 매우 효과적이다. LLM\\n을 통해 자동화된 데이터 분석이 가능해지며, 임상시험 전반\\n에서 더 신뢰할 수 있는 결과를 도출할 수 있다.\\n의료기기 임상시험은 제품의 안전성과 유효성을 검증하\\n는 중요한 과정으로, 데이터 분석의 정확성과 신뢰성이 매\\n우 중요한 역할을 한다. 기존의 통계적 분석 방법은 대규\\n모 데이터를 효과적으로 처리하는 데 한계가 있었고, 이는 \\n임상시험 과정에서 오류와 지연을 초래할 수 있었다. LLM \\n기반 생성형 AI는 이러한 문제를 해결할 수 있는 가능성을 \\n보여주고 있다. 특히 LLM은 기존 통계적 방법론과 달리, \\n데이터의 양과 복잡성에 구애받지 않고 패턴을 분석하고 \\n중요한 정보를 추출할 수 있다. \\n본 연구는 LLM 기반 생성형 AI가 임상시험에 어떻게 \\n적용될 수 있는지에 대해 구체적인 방법을 제시하고, 이를 \\n통해 임상시험의 신뢰성과 효율성을 어떻게 향상시킬 수 \\n있는지를 분석한다 [10]. 구체적으로 LLaMA와 같은 오픈\\n소스 모델을 사용하여 임상 데이터를 분석하고, 이를 통해 \\n더 신속하고 정확한 결과를 도출하는 방법을 제안한다. 또\\n한 이러한 기술이 의료기기 개발과 임상시험에서 혁신을 \\n가져올 수 있는 가능성을 평가하며, 향후 임상시험에서 \\nLLM 기술의 확장 가능성도 논의한다.\\nLLM 기반 기술은 단순히 데이터를 분석하는 것 이상의 \\n의미를 지니고 있다. 임상 데이터에서 발견된 패턴을 바탕\\n으로 의사결정을 돕고, 궁극적으로는 임상시험의 전반적인 \\n효율성을 높일 수 있는 중요한 도구로 활용될 수 있다.[5] \\n이 연구는 LLM 기술이 임상시험뿐만 아니라 다양한 의료 \\n분야에서 데이터 분석의 패러다임을 변화시킬 수 있는 가\\n능성을 제시한다. 향후 LLM을 활용한 의료기기 개발 및'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 2}, page_content='Clinical Trials Utilizing LLM-Based Generative AI   171\\n임상시험에서의 발전 방향을 제시하며, 이를 통해 의료 분\\n야 전반에서 혁신적인 변화를 이끌어내고자 한다.\\nII. Preliminaries\\n1. Limitations of Traditional NLP Approaches \\nand Advantages of LLMs in Healthcare\\n기존의 자연어 처리(NLP) 방법은 통계적 분석기법과 결\\n합하여 의무기록, 임상 노트, 의료 문헌 등의 비정형 임상\\n시험 데이터를 분석하는 데 기본적인 역할을 해왔습니다. \\n그러나 현대의 의료 및 임상 작업에 적용할 경우, 특히 대\\n규모 언어 모델(LLM)의 기능과 비교할 때 상당한 한계에 \\n직면합니다. \\ny 기존 NLP 알고리즘은 종종 사전 정의된 규칙 기반 시\\n스템에 의존했으며, 이는 다양한 의료 도메인에 대한 \\n적응력이 떨어졌습니다.\\ny 의료 데이터의 미묘한 차이와 복잡성을 이해하거나 \\n맥락을 보존하는 데 어려움이 있었습니다.\\ny 의료 용어의 다양성과 지역적 규제 차이를 다루는 데 \\n제약이 있었습니다.\\ny 기존 NLP는 새로운 의료 도메인에 적응하려면 대규모\\n의 도메인 특화 데이터와 레이블 작업이 필요합니다.\\nTable 1과 같이 대규모 언어 모델(LLMs)은 기존 NLP\\n의 한계를 극복하며, 의료 분야에서 이러한 한계를 극복하\\n는 방법으로 LLM접근 방법을 강조합니다.[17][18][19] \\nFeatures\\nTraditional NLP\\nLLMs\\nAccuracy\\nRelies on \\nrule-based \\nsystems\\nExcels in understanding \\nmedical contexts\\nData \\nHandling\\nLimited to \\ntext-based data\\nCapable of integrating \\nmultimodal data\\nAdaptability\\nRequires \\nextensive \\ndomain-specific \\ntraining\\nAdapts quickly with \\nFew-shot and \\nZero-shot learning\\nApplications\\nBasic text \\nanalysis\\nSupports clinical \\ndecision-making, \\nmedical education\\nTable 1. Comparison of Traditional NLP Methods \\nand Large Language Models (LLMs) in Healthcare\\n또한 Table 2와 같이 기존의 자연어 처리(NLP) 방법이\\n나 통계기법이 혼용된 머신러닝 기법은 본 연구과제와 유\\n사한 적용분야인 의료분야의 개인화된 질의시스템을 만드\\n는데 있어서는 GPT4 이후의 모델에 대해서는 정확도와 \\nF1 Score에 있어서 현저히 성능이 떨어진다.[20]\\nTable 2. Comparison of NLP/ML Approaches and\\nLLM Models in Accuracy and F1 Score\\n따라서, 본 연구에서는 의료기기 임상시험에서 활용되\\n는 정형, 비정형 데이터 분석과 의사결정 지원을 자연어의 \\n맥락을 이해하지 못한 통계적 방법에서 탈피하고, 기존의 \\nNLP에서 접근 한계를 극복하고자 LLM 접근으로 시도하\\n였다.\\n2. Related works\\n2.1 Domestic trends\\n한국에서는 대규모 언어 모델(LLM)을 임상시험에 적용\\n하는 연구가 학계와 연구 기관을 중심으로 활발히 진행되\\n고 있다. KAIST, 서울대학교, 연세대학교와 같은 주요 대\\n학들이 의료 데이터 분석과 예측 모델링에 LLM을 통합하\\n기 위한 노력을 주도하고 있다. 예를 들어, KAIST는 대규\\n모 임상 데이터를 분석해 질병 결과를 예측하는 LLM 기반 \\n모델을 개발했으며, 이 모델은 향후 임상시험에서 중요한 \\n역할을 할 것으로 예상된다. \\n한국보건산업진흥원(KHIDI) 또한 LLM을 활용해 의료 \\n데이터 분석을 통합하는 여러 프로젝트를 지원하고 있다. \\n이러한 프로젝트는 대규모 데이터에서 숨겨진 패턴을 발\\n견해 임상시험의 효율성과 정확성을 향상시키는 것을 목\\n표로 하고 있다. 한국 의료 부문에서 LLM의 도입이 가속\\n화되고 있으며, 이는 Table 3와 같이 AI가 임상 실무를 혁\\n신할 잠재력이 크다는 것을 보여준다.'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 3}, page_content='172   Journal of The Korea Society of Computer and Information \\nInstitution\\nApplication \\nArea\\nDescription\\nKAIST\\nDisease \\nOutcome \\nPrediction\\nDeveloping a model to \\npredict disease \\noutcomes using LLM\\nSeoul \\nNational \\nUniversity\\nMedical Data \\nAnalysis\\nUsing LLM for \\ncomprehensive \\nanalysis of medical \\ndata\\nKorea Health \\nIndustry \\nDevelopment \\nInstitute \\n(KHIDI)\\nIntegrated \\nMedical Data \\nAnalysis\\nSupporting an LLM \\nproject to develop \\nclinical trial policies\\nTable 3. Key Applications of LLM in Clinical Trials \\n- domestic trends\\n2.2 A foreign trend\\n전 세계적으로 LLM 기반 생성형 AI의 임상시험 통합이 \\n빠르게 진행되고 있으며, 주요 기술 기업과 연구 기관들이 \\n이를 주도하고 있다. Table 4와 같이 Google Health와 \\nIBM Watson Health는 대규모 전자 건강 기록(EHR)을 분\\n석해 진단 정확성과 질병 예측을 개선하기 위해 LLM을 활\\n용하고 있다 [3]. Google Health의 EHR 분석에서 LLM을 \\n활용한 결과는 질병 패턴을 정확히 식별해 임상시험 설계\\n를 더욱 정밀하게 할 수 있다는 것을 보여준다.\\n영국에서는 DeepMind의 AlphaFold가 제약 산업에 큰 \\n영향을 미치고 있다. AlphaFold는 단백질 접힘 패턴을 정\\n확하게 예측하여 신약 개발에 중요한 역할을 하고 있다 \\n[4]. 이와 같은 성과는 LLM이 임상시험을 변화시키고 새\\n로운 치료법 개발을 가속화할 잠재력을 보여준다.\\n미국의 Stanford University와 MIT와 같은 학술 기관들\\n도 LLM의 생의학 연구 활용 가능성에 많은 투자를 하고 있\\n다. 그들의 연구는 LLM이 생의학 데이터에서 전통적인 분\\n석 방법으로는 발견할 수 없는 복잡한 패턴을 식별함으로써 \\n임상시험의 정확성을 높일 수 있음을 입증하고 있다 [7].\\nInstitution\\nApplication \\nArea\\nDescription\\nGoogle \\nHealth\\nEHR \\nAnalysis\\nImproving disease \\nprediction and diagnostic \\naccuracy using LLM\\nDeepMind\\nProtein \\nFolding \\nPrediction\\nApplying LLM to accurately \\npredict protein structures\\nStanford \\nUniversity\\nBiological \\nData \\nAnalysis\\nEnhancing the accuracy of \\nclinical trials using LLM\\nTable 4. Key Applications of LLM in Clinical Trials \\n- international trends\\n2.3 Theoretical background\\n임상시험에서 대규모 언어 모델(LLM)의 적용은 자연어 \\n처리(NLP)와 같은 여러 이론적 프레임워크에 기반을 둔다. \\nNLP는 LLM이 인간의 언어를 이해, 처리, 생성할 수 있도\\n록 한다. LLM은 주로 트랜스포머와 같은 딥러닝 아키텍처\\n를 사용해 방대한 양의 텍스트 데이터를 처리하고 의미 있\\n는 패턴을 추출한다 [6]. 의료기기 임상시험에서 이러한 모\\n델은 시험 데이터를 분석하고, 상세한 보고서를 생성하며, \\n과거 데이터를 기반으로 결과를 예측해 의사결정 과정을 \\n향상시킬 수 있다.\\n2.4 Technical Implementation\\nLLM 기반 생성형 AI를 임상시험에 구현하기 위해서는 \\n일련의 기술적 단계를 거쳐야 한다. 우선, 의료기기 및 임\\n상 데이터와 관련된 대규모 데이터셋을 학습시키는 과정\\n이 필요하다. 이 과정에는 많은 계산 능력과 고품질 데이\\n터에 대한 접근이 요구된다.[9] \\n데이터 수집 단계에서는 다양한 출처의 임상 데이터를 \\n확보하고, 이를 적절하게 전처리해야 한다. 데이터 전처리\\n는 LLM 모델의 성능에 큰 영향을 미치며, 특히 임상 데이\\n터를 텍스트 형식으로 통일하거나 필요한 경우 이미지를 \\n포함한 비정형 데이터를 처리하는 작업이 필요하다. \\n전처리된 데이터는 LLaMA와 같은 오픈소스 LLM 모델\\n을 사용해 학습되며, 이 과정에서 PEFT(LoRA) 및 RAG \\n(Retrieval-Augmented Generation) 기법을 적용해 모델\\n을 최적화한다. 이러한 최적화 과정은 임상 데이터 분석의 \\n정확성을 향상시키는 중요한 요소로 작용한다. 또한, 모델\\n이 의료기기 임상시험에서 발생하는 다양한 복잡한 데이\\n터를 효과적으로 처리할 수 있도록 조정한다 [8]. \\nLLM이 학습된 후, 이를 임상시험 과정에 통합하여 실\\n시간으로 데이터를 분석하고 그 결과를 도출한다. 학습된 \\nLLM은 임상 데이터를 처리하고, 패턴을 찾아내며, 결과를 \\n예측하는 데 중요한 역할을 한다. 특히, 자동화된 분석 과\\n정을 통해 임상시험의 속도를 높이고, 신뢰할 수 있는 결\\n과를 빠르게 도출하는 것이 가능하다. 이러한 기술적 구현\\n은 임상시험의 효율성을 극대화하는 데 기여할 수 있다.\\n2.5 A method of research\\n본 연구에서는 여러 사례 연구를 통해 LLM 기반 생성\\n형 AI의 임상시험에서의 효과를 평가한다. 예를 들어, \\nGoogle Health는 LLM을 활용해 대규모 환자 기록 데이\\n터를 분석하여, 위험 요소를 식별하고 환자 결과를 개선하\\n는 데 기여했다. 이 연구에서는 대규모 데이터를 처리하는'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 4}, page_content='Clinical Trials Utilizing LLM-Based Generative AI   173\\nLLM이 기존의 분석 방법보다 더 신뢰할 수 있는 결과를 \\n도출할 수 있음을 보여주었다. 또 다른 사례로, DeepMind\\n의 AlphaFold는 단백질 접힘 패턴을 예측하는 데 사용되\\n었으며, 이는 신약 개발 및 치료법 연구에서 중요한 역할\\n을 한다. 본 연구에서는 임상시험 데이터에서 얻을 수 있\\n는 복잡한 패턴을 분석하고, 이러한 패턴이 임상시험 결과\\n에 미치는 영향을 평가하는 방법을 사용한다. 특히, LLM \\n기반 모델을 이용해 데이터를 자동으로 분류하고, 분석된 \\n정보를 바탕으로 임상시험의 신뢰성을 높일 수 있었다. 이\\n러한 연구 방법은 임상시험 과정에서 발생하는 다양한 데\\n이터를 처리하고, 분석 결과를 더욱 신속하고 정확하게 도\\n출하는 데 중요한 역할을 한다.\\nLLM 기반 AI의 적용은 기존 분석 방법과 비교했을 때 \\nTable 5와 같이 데이터 처리 속도와 분석의 정확성 측면\\n에서 많은 이점을 제공한다. 특히, 복잡한 데이터셋을 효\\n율적으로 처리하고, 분석 결과에 따라 빠르게 의사결정을 \\n내릴 수 있는 능력을 갖추고 있다. 본 연구는 이러한 기술\\n적 접근법이 임상시험에서 어떻게 효과적으로 적용될 수 \\n있는지를 제시하고 있으며, 앞으로 더 많은 사례 연구를 \\n통해 LLM 기반 AI의 활용 가능성을 탐구할 계획이다.[15]\\nBenefit\\nDescription\\nImproved \\nAccuracy\\nLLM enhances the accuracy of data \\nanalysis.\\nTime \\nEfficiency\\nAutomated processes reduce the time \\nrequired for analysis.\\nDetailed \\nInsights\\nLLM provides detailed insights to \\nsupport medical decision-making.\\nScalability\\nLLM can handle large datasets smoothly.\\nTable 5. Key Benefits of LLM-Based Analysis in\\nMedical Device Clinical Trials\\nIII. The Proposed Scheme\\n본 연구에서는 의료기기 임상시험에 특화된 Private \\nLLM 접근 방법을 제안한다. 이 접근 방법은 도메인 특화 \\n데이터셋 구축, LLM 모델 튜닝, 도메인 특화 프롬프트 적\\n용, 그리고 도메인 특화 기능 구현의 네 가지 핵심 단계로 \\n구성된다. 각 단계는 의료기기 임상시험 분야의 특수성을 \\n반영하여 상호 유기적으로 작동하며, Figure 1와 같이 이\\n를 통해 해당 분야에서 최적의 성능을 달성하도록 설계되\\n었다.\\nFig. 1. Clinical Trial Specialized Private LLM Approach\\n1. Building Domain-Specific Datasets\\n1.1 Data Collection\\n의료기기 임상시험에 특화된 Private LLM을 효과적으\\n로 구축하기 위한 첫 번째 단계로, 도메인 특화 데이터셋\\n을 구축하였다. 이러한 특화된 데이터셋은 의료기기 임상\\n시험의 특수성을 반영하여 모델 학습 및 최적화 과정에서 \\n직접적이고 중요한 영향을 미친다[11].\\n의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\ny 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\ny 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\ny 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\ny 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\ny 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 \\n데이터셋은 \\n의료기기 \\n임상시험에 \\n특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 5}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement\\nApplication Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation \\nProcessing\\nFilters sensitive personal \\ninformation in clinical trial data \\nthrough entity masking and filtering\\nText Refinement\\nProcesses transcription and \\nremoves noise through methods \\nlike normalization, sentence \\nsegmentation, and correction\\nSentence \\nSegmentation\\nBreaks down paragraphs and \\nsentences to structure text into \\nanalyzable units\\nKeyword \\nExtraction\\nExtracts keywords with significant \\nmeaning from the text\\nTokenization\\nDivides text into analyzable units by \\nidentifying individual words or \\nmeaningful phrases\\nTable 6. Data preprocessing process\\n이렇게 구축된 도메인 특화 데이터셋은 모델의 성능에 \\n직접적인 영향을 미치므로, 데이터의 품질과 정확성을 확\\n보하기 위해 전처리 결과에 대한 전문가의 점검을 진행하\\n였다.\\n2. Tuning domain-specific LLM models\\n2.1 Select and tune the base model\\n도메인 특화 LLM 모델 튜닝은 메타(Meta)의 오픈소스 \\n대규모 언어 모델인 LLaMA를 기반으로 수행하였다. \\nLLaMA 모델은 의료기기 임상시험 데이터로 파인튜닝되\\n었으며, 도메인 특화 데이터셋을 활용하여 지속적인 사전 \\n학습을 Figure 2와 같이 진행하였다. \\n모델 튜닝 기법으로 Parameter-Efficient Fine-Tuning \\n(PEFT) LoRA(Low-Rank Adaptation)를 적용했다. PEFT는 \\n기존 모델의 파라미터를 직접 수정하지 않으면서도 특정 작업\\n에서 성능을 향상시키는 효과적인 기술이다. \\nLoRA(Low-Rank Adaptation)는 PEFT의 한 방식으\\n로, 모델의 특정 변환기 층의 파라미터를 저랭크 행렬로 \\n표현하여 업데이트한다. 이를 통해 전체 파라미터를 재훈\\n련하는 대신, 저랭크 행렬을 활용해 파라미터 변경 범위를 \\n줄임으로써 메모리와 계산 자원의 효율성을 높였다.\\n튜닝된 모델을 통해 임상시험 프로토콜 분석, 안전성 모\\n니터링, 규제 준수 문서화 등 다양한 작업에서 효과적인 \\n답변을 제공할 수 있도록 지원하였다. 또한, 점진적인 조\\n정을 통해 모델이 도메인 내에서 점차적으로 최적화되도\\n록 하여 임상시험 특화 도메인 환경에서의 응용 가능성을 \\n높였다.\\nFig. 2. Fine Tuning application code'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 6}, page_content='Clinical Trials Utilizing LLM-Based Generative AI   175\\n2.2 Create search augmentation:advance RAG applied\\n검색 증강 생성(Advance RAG) 기법은 임상시험 데이\\n터베이스에서 필요한 정보를 검색하여 모델이 더 정확한 \\n응답을 생성하도록 지원한다. 이 기법은 모델에 대한 파인 \\n튜닝과 더불어 특히 복잡한 의료 데이터와 임상시험의 다\\n양한 요구 사항을 처리하는 데 유용하다. 검색 증강 생성\\n(Advance RAG)은 모델이 처리하지 못한 답변을 보완하\\n여 모델의 성능을 향상시키는 데 중요한 역할을 한다. 특\\n히, 검색된 정보를 응답 생성 과정에 통합하여 정보의 정\\n확성과 신뢰성을 높였다. 이 기법을 통해 Figure 3와 같은 \\n유용성을 추구하였다.\\ny 최신 정보 반영: 데이터 업데이트로 인한 최신 정보를 \\n반영하여 모델의 적응성을 향상했다.\\ny 정확성 및 신뢰성 향상: 검색된 정보를 응답 생성 과정\\n에 통합하여 모델의 정보 정확성과 신뢰성을 높였다.\\nFig. 3. Search Augmentation Apply Code\\n본 연구는 기존 연구에서 활용된 LLaMA, PEFT, \\nLoRA, RAG 등의 기법을 기반으로 하지만, 다음과 같은 \\n고유한 기술적 기여를 통해 기존 연구 대비 차별성을 확보\\n하였다.\\ny 도메인 특화 데이터셋 구축 및 튜닝: 기존 연구들은 \\n일반적인 의료 데이터 분석에 초점을 맞췄으나, 본 연\\n구는 임상시험 데이터의 특성을 반영한 전문가 주도\\n형 데이터셋 구축과 이를 기반으로 한 모델 튜닝을 \\n통해 분석 정확도를 향상시켰다.\\ny Advance RAG의 맞춤형 통합: 기존의 RAG는 단순히 \\n정보 검색 및 통합에 활용되었지만, 본 연구에서는 실\\n시간 데이터 보강 및 응답 신뢰도 향상을 위해 임상시\\n험 환경에 맞춘 RAG 구조를 새롭게 설계하였다. 이를 \\n통해 데이터의 최신성과 정확성을 동시에 확보하였다.\\ny PEFT 및 LoRA의 최적화 응용: 메모리 및 계산 효율성\\n을 유지하면서도 도메인 특화 학습을 지원하기 위해 저\\n랭크 행렬 업데이트 기법을 고도화하였다. 이는 기존 \\nPEFT 기반 연구와 비교해 학습 비용을 30% 이상 절감\\n하면서도 BLEU 점수에서 15%의 향상을 가져왔다.\\ny LLM 기반 임상시험 데이터 분석 자동화: 기존 통계적 \\n방법론이 처리할 수 없었던 비정형 데이터의 패턴 탐\\n지를 가능하게 함으로써 임상시험 설계와 데이터 분\\n석의 전반적인 속도와 신뢰성을 강화하였다.\\n3. Applying Domain-Specific Prompts\\n3.1 Considerations in Prompt Engineering\\n임상시험 관련 작업은 고도의 전문성과 정확한 데이터 \\n처리가 요구되는 분야로, 일반적인 언어 모델만으로는 특\\n정 용어의 정확한 인식과 문맥 처리가 어렵다. 따라서 도\\n메인 특화 프롬프트를 구현하여 LLM의 성능을 특정 임상\\n시험 작업에 최적화하는 작업이 필요하다. \\n또한 Figure 4와 같이 시스템 차원에서 프롬프트 설정\\n을 통해 모델의 일관성과 정확성을 더욱 높일 수 있다. 특\\n히 도메인 특화 LLM의 정확성과 일관성을 보장하기 위해 \\n프롬프트의 시스템 설정이 중요하다.\\nFig. 4. System Role Settings Prompt\\n답변생성에 대한 도메인 특화 프롬프트 설계는 다음 네 \\n가지 주요 구성 요소를 기반으로 한다[12].\\ny 지시(Instruction): 모델에게 수행할 구체적인 작업을 \\n명확하게 지시한다.\\n- 예: \"임상시험 데이터에서 사용되는 용어와 그 정의\\n를 추출하라.\"\\ny 문맥(Context): 임상시험의 특정 상황이나 데이터셋\\n에 대한 배경 정보를 제공하여 모델이 더 정확한 결\\n과를 도출할 수 있도록 지원한다.\\ny 입력 데이터(Input Data): 직접 처리할 임상시험 데이\\n터나 문서를 모델에 입력한다.\\ny 출력 지시자(Output Directive): 모델에게 결과를 어떤 \\n형식으로 출력할지 지시한다.\\n- 예: \"추출된 용어와 정의를 리스트 형태로 반환하라.\"'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 7}, page_content='176   Journal of The Korea Society of Computer and Information \\n3.2 Prompting Techniques Application\\n임상시험 특화 Private LLM을 위해 Few-shot Learning, \\nCOT(Chain-of-Thought) \\nPrompt \\nEngineering \\nTechniques를 Figure 5와 같이 적용하였다.\\ny Few-shot Learning: 임상시험 관련 몇 가지 예제를 \\n모델에 제공하여 특정 작업에 대해 빠르게 학습하고 \\n적응하도록 한다. 이는 다양한 임상시험 용어와 해당 \\n정의를 몇 개만 제시하여 모델이 패턴을 인식하도록 \\n돕는다. LLaMA 모델의 경우, Few-shot 학습을 통해 \\n강력한 성능이 입증되었다[13].\\ny Chain-of-Thought Prompting: LLM에서 복잡한 추\\n론 작업을 수행할 수 있도록 중간 추론 단계를 생성하는 \\n방법이다. 이는 임상시험과 같은 특수한 영역에서 프롬\\n프트의 문제를 해결하는 데 효과적이다[14]. \\nFig. 5. Implementation Code for Prompt Engineering\\n4. Implement domain-specific features\\n4.1 Answer processing function classification\\n임상시험 특화된 Private LLM시스템의 기능은 기본적\\n으로 두 가지 방식으로 구분하여 구현하였다:\\ny Information Driven Response: 도메인의 학습 지식\\n을 바탕으로 대답하는 방식이다. 이는 규제 및 데이터 \\n정확성이 요구되는 질의에 집중하여 정확하고 신뢰성 \\n있는 정보를 제공한다.\\ny Generic Response: LLM에 내장된 기본 지식으로 답\\n변하는 방식이다. 이는 일반적이고 유연한 응답을 제\\n공함으로써 사용자 경험을 향상시킨다.\\n이러한 구분은 임상시험과 관련된 사용자가 특화된 분\\n야에 맞춤형 답변을 필요로 함과 동시에 범용적이고 일반\\n적인 상식의 답변을 요구하기 때문이다. 두 가지 기능적 \\n구분을 통해 LLM 시스템은 도메인 지식의 정확성과 일반\\n적 응답 처리 능력을 모두 활용하여 임상시험과 같은 특수\\n한 도메인 환경에서 효율적이고 신뢰성 있는 응답을 제공\\n할 수 있다.\\n4.2 Implementing a functional structure that \\nconsiders users and administrators\\n특화된 LLM 시스템을 구축할 때, 사용자 중심 설계와 관\\n리자 중심 설계를 동시에 고려하는 것은 시스템의 효율성\\n과 유지 보수성, 그리고 사용자 경험 향상에 중요한 역할을 \\n한다. Figure 6의 기능 구조도와 Figure 7 메인 화면처럼, \\n사용자와 관리자 두 가지 사용자 그룹의 요구 사항을 반영\\n하여 시스템을 구현하였다. 결과적으로, 사용자 중심의 편\\n의성과 관리자 중심의 효율성이 상호 보완적으로 작용하여 \\n전체 시스템의 효율성과 안정성을 극대화한다.\\ny 사용자 기능: 사용자 중심의 간편한 인터페이스를 제\\n공하여 필요한 정보를 신속하고 정확하게 얻을 수 있\\n도록 한다.\\ny 관리자 기능: 관리자 중심의 강력한 제어 기능을 제공하\\n여 시스템의 유지 보수와 업데이트를 용이하게 한다.\\nFig. 6. Domain-specific functional structural diagram\\nFig. 7. Clinical Trial Specialized Private LLM Main Screen'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 8}, page_content='Clinical Trials Utilizing LLM-Based Generative AI   177\\nIV. Performance Evaluation\\n1. Rationale for Selecting GPT-4 as a Comparative \\nBenchmark\\nGPT-4는 주요 의료 데이터셋에서 최상의 성능을 기록\\n하며, 본 연구에서 Private LLM의 벤치마킹 대상으로 선\\n정되었습니다. 특히, USMLE, MedMCQA, PubMedQA 세 \\n가지 주요 의료 데이터셋에서 GPT-4의 정확도는 최신 의\\n료 특화 LLM과 비교하여 최고 수준을 나타냅니다. 이는 \\nTable 7에 요약된 성능 데이터로 명확히 확인됩니다.[16]\\nTable 7. Avg. Deviation of Models Compared to\\nHuman Performance[16]\\nTable 7는 각 데이터셋에서 GPT-4가 Human 수행 성\\n과와의 편차(Deviation) 값에서 가장 낮은 값을 기록하며, \\n의료 분야에서 최고 수준의 일관성과 정확도를 달성했음\\n을 보여줍니다. 이는 의료기기 임상시험 분야에서 Private \\nLLM과의 성능 비교를 위한 가장 신뢰할 수 있는 기준점으\\n로 평가됩니다. 따라서 본 연구는 GPT-4를 벤치마크 모델\\n로 선택하였다.\\n2. Select Performance Evaluation Indicators\\n본 의료기기 임상시험에 적용하려는 기능인 의료 분야\\n의 Text Generation과 Question Answering Systems의 \\n평가에 적합한 지표로 BLEU, ROUGE, EM, F1 Score 등\\n이 제시되었다[17]. 기존의 EM(Exact Match)은 단어가 \\n정확히 일치해야 점수를 부여하므로, GPT-4와 Private \\nLLM이 같은 의미를 다르게 표현하는 경우를 반영하지 못\\n한다. 이를 보완하기 위해 SAS를 활용하여 생성된 답변의 \\n의미적 유사성을 평가하며, 단순한 문자 매칭을 넘어 문맥\\n적 의미를 중시하였다. 기타 언급된 지표는 단일 답변적용 \\n불가능이나, 의미적 품질 직접 평가 불가능하거나 여러 참\\n조 텍스트를 활용하여, 본 연구에서 적용하려는 시스템과 \\n거리가 먼 내용이다. 본 연구에 있어서는 SAS (Semantic \\nAnswer Similarity), BLEU, ROUGE을 도입하여, 상호 보\\n완성을 추구하였다. 비교 모델은 답변 검증을 위해 \\nOpenAI사의 ChatGPT GPT4에 대해서 임상전문가의 역\\n할을 부여하여 비교 했다. 속도적 검증은 하드웨어 자원의 \\n종속성이 있어 논외로 한다. 도입된 평가지표는 Table 8\\n에 기술되어있는 바와 같이, BLEU, ROUGE, SAS로 LLM \\n분야의 성능측정에서 많이 사용되는 지표이다.\\nEvaluation Metric\\nApplication Basis\\nBLEU \\n(Bilingual Evaluation \\nUnderstudy): \\nMeasures similarity between \\ngenerated and reference text; \\nprimarily compares with source text\\nROUGE \\n(Recall-Oriented \\nUnderstudy for \\nGisting Evaluation)\\nEvaluates text summary relevance, \\nnatural language\\nSAS(Semantic \\nAnswer Similarity)\\nEnables evaluation of semantic \\nalignment\\nTable 8. Performance Evaluation Indicators\\n3. Performance Evaluation Indicators Comparison \\nResults\\n성능 비교를 위한 진행은 임상시험에 관련된 특화 질문\\n리스트를 마련해서 질문을 random하게 샘플링을 수행해\\n서 두 LLM의 성능에 대한 비교분석을 Table 9와 같이 진\\n행하였다.\\nTable 9. Evaluation index measurement results \\n(Samples = 200)\\n3.1. Comparison of BLEU scores\\nBLEU Score는 텍스트 생성에서 주로 사용되는 정확도 \\n기반의 메트릭으로, 생성된 텍스트가 레퍼런스와 얼마나 \\n일치하는지를 측정했다.\\ny Private LLM: 평균 BLEU 점수는 2.059로, 여전히 낮\\n은 값을 보였지만 최대값이 62.597로 특정 사례에서\\n는 매우 높은 성능을 보였다. 표준편차가 7.503으로 \\n크기 때문에, 일부 질문에서는 높은 성능을 발휘하는 \\n것으로 보인다.\\ny ChatGPT: 평균 BLEU 점수는 0.570로, Private LLM\\n보다 낮다. 최대값이 11.484로, Private LLM에 비해'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 9}, page_content='178   Journal of The Korea Society of Computer and Information \\n일관되게 높은 성능을 보이지는 않았다.\\nBLEU 관점에서 Private LLM이 ChatGPT보다 도메인 \\n특화 질문에 대해 더 높은 성능을 보이는 경향이 있지만, \\n일부 질문에서는 낮은 성능을 보일 수 있다. 이는 Private \\nLLM의 특정 도메인에 대한 높은 적응력과 그 외 질문에 \\n대한 성능 편차를 시사한다.\\n3.2. ROUGE Score Comparison (Precision, Recall, F1)\\nROUGE는 생성된 텍스트가 레퍼런스와 얼마나 겹치는\\n지를 보는 메트릭으로, Precision, Recall, F1-Score가 \\n포함된다.\\ny Private LLM: Precision 평균값은 0.190, Recall은 \\n0.817, F1-Score는 0.293으로 나타났다. Private \\nLLM이 상대적으로 높은 Recall 값을 보이고 있어, \\n더 많은 정보를 포괄하는 경향을 나타내고 있다.\\ny ChatGPT: Precision 평균값은 0.111, Recall은 \\n0.226, F1-Score는 0.140으로, Private LLM에 비\\n해 상대적으로 낮은 성능을 보였다. 특히 정보의 포\\n괄성(Recall)에서 \\n큰 \\n차이를 \\n보이며, \\n정확성\\n(Precision) 또한 낮다.\\nROUGE 점수에서는 Private LLM이 ROUGE Recall에\\n서 확연히 높은 성능을 보여주고 있다. 이는 질문에 맞는 \\n더 많은 정보를 제공하는 경향을 나타낸다. 하지만 \\nPrecision이 낮아 포괄된 정보의 정확도는 개선이 필요하\\n다. 반면 ChatGPT는 정보 포괄 능력이 상대적으로 낮으\\n나, Precision 측면에서 약간 더 안정적일 수 있다.\\n3.3. SAS (Semantic Answer Similarity) comparison\\nSAS는 생성된 텍스트가 레퍼런스와 의미적으로 얼마나 \\n유사한지 측정하는 메트릭이다. 코사인 유사도와 유클리드 \\n거리로 측정했다.\\ny Private LLM: SAS Cosine 평균값은 0.640, SAS \\nEuclidean 평균값은 0.075로 나타났다.\\ny ChatGPT: SAS Cosine 평균값은 0.616, SAS \\nEuclidean 평균값은 0.073으로 나타났다.\\nSAS 점수에서 Private LLM이 다소 우세한 성능을 보\\n였으나, ChatGPT와 큰 차이를 보이지는 않았다. 두 모델 \\n모두 의미적 유사성 측면에서 비슷한 성능을 보이고 있으\\n며, Private LLM이 약간의 우위를 점하고 있다.\\n3.4. Comparison of answer lengths\\ny Private LLM: 평균 답변 길이는 100.525로 나타났으\\n며, 최대 235글자였다.\\ny ChatGPT: 평균 답변 길이는 281.210로 Private \\nLLM보다 약 3배 긴 답변을 생성하는 경향을 보였다. \\n최대 길이는 844글자에 이르렀다.\\n3.5. Practical Limitations in Clinical Applications\\nChatGPT는 Private LLM에 비해 더 긴 답변을 생성하\\n는 경향이 있으나, 길이가 길다고 반드시 더 나은 성능을 \\n의미하지는 않는다. Private LLM은 상대적으로 더 짧고 \\n간결한 답변을 제공하며, 이는 특정 도메인에서 중요한 신\\n뢰도와 정확성을 제공할 수 있다. 그러나 본 연구는 LLM \\n기반 분석의 효율성과 신뢰성을 강조하며, 이를 실제 임상\\n시험 환경에 적용하기 위해서는 몇 가지 실질적인 제한 사\\n항을 고려해야 한다. \\n첫째, 의료 데이터의 민감성과 데이터 프라이버시 문제\\n는 LLM 모델 학습 과정에서 중요한 제약으로 작용한다. \\n의료 데이터의 보안과 규제 요건을 충족하기 위해 암호화 \\n기술이나 프라이버시 보호 알고리즘의 도입이 필요하다. \\n둘째, LLM 모델이 생성한 결과의 신뢰성을 보장하기 \\n위한 추가적인 검증 절차가 요구된다. 이를 위해 도메인 \\n전문가의 피드백과 지속적인 검증 과정을 설계해야 하며, \\n특히 자동화된 분석 결과에 대한 해석 가능성을 강화하는 \\n기술적 접근이 필요하다. \\n셋째, 도메인 특화된 성능 평가 기준이 추가적으로 마련\\n되어야 한다. 기존의 일반적인 성능 지표는 의료기기 임상\\n시험과 같은 고도로 특화된 영역에서 충분하지 않을 수 있\\n다. 따라서 해당 분야의 특수성을 반영한 새로운 성능 지\\n표를 개발하는 것이 중요하다. 이러한 제한 사항들을 해결\\n하기 위한 기술적·정책적 접근이 향후 연구에서 다뤄져야 \\n할 중요한 과제로 남아 있다.\\nV. Conclusions\\n본 연구에서는 임상시험 분야에서 text to text 기반의 \\nPrivate LLM을 구현하고, 그 성능을 ChatGPT 모델과 비\\n교하였다. BLEU, ROUGE, SAS(Semantic Answer \\nSimilarity)와 같은 다양한 성능 지표를 통해 종합적인 성\\n능 분석을 진행한 결과, Private LLM이 ChatGPT 대비 \\n전반적으로 우수한 성능을 보였다. 특히 ROUGE Recall \\n및 SAS Cosine에서 Private LLM이 ChatGPT보다 더 높\\n은 성과를 기록하며, 출처 기반 정보를 포괄하고 의미적 \\n일관성을 유지하는 데 있어 Private LLM이 강점을 가지\\n고 있음을 확인했다.'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 10}, page_content='Clinical Trials Utilizing LLM-Based Generative AI   179\\n이러한 결과는 Private LLM이 임상시험 문서에 특화된 \\n질문과 답변을 더 정확하게 생성할 수 있음을 보여준다. \\n도메인 특화 튜닝이 이루어질수록, Private LLM은 임상 \\n연구자와 사용자가 필요로 하는 정보를 더욱 신뢰할 수 있\\n는 방식으로 제공할 수 있다. BLEU와 ROUGE 점수를 통\\n해 확인된 바와 같이, Private LLM은 ChatGPT보다 출처 \\n기반의 정확도에서 강점을 보이며, 정보의 포괄성과 의미\\n적 유사성 면에서도 우위를 점하고 있다.\\n그러나 text to text 기반 LLM은 여전히 개선의 여지가 \\n있다. 모델의 튜닝이 현재 임상시험 텍스트에 기반해 이루\\n어졌지만, 더 다양한 내용의 학습 문장 표현과 추론 능력\\n을 보완할 필요가 있다. 또한 경우에 따라서는 ChatGPT\\n의 더 긴 답변을 생성하면서 추론하는 능력을 혼합적으로 \\n사용하도록 접목할 필요도 있다. \\n또한, 이번 연구는 text to text 방식에 국한되었으나, \\n향후 발전 방향으로 멀티모달 LLM 접근을 통해 텍스트 외\\n에도 이미지, 동영상, 음성 등 다양한 비정형 데이터를 처\\n리하는 시스템으로 확장할 수 있을 것이다. 이러한 멀티모\\n달 모델은 임상시험 문서뿐만 아니라 의료 이미지와 같은 \\n시각적 정보를 결합하여 더 풍부한 응답을 생성할 수 있을 \\n것이며, 이를 통해 사용자의 요구에 보다 잘 부합하는 맞\\n춤형 솔루션을 제공할 수 있을 것이다.\\n따라서 Private LLM의 성능 향상은 지속적인 사용자 \\n피드백과 최적화 과정을 통해 더욱 고도화될 수 있으며, \\n이를 통해 임상시험 분야에서의 실질적인 활용도가 크게 \\n향상될 것으로 기대된다. 추가적으로 Table 10과 같이 의\\n료기기 임상전문가 양성사업을 통해 LLM 기반 전산 플랫\\n폼 교육 진행 결과 53명 대상으로 도출된 LLM 기반 전산 \\n플랫폼 교육 만족도 조사표이다.\\nCategory\\nAverage Score \\n(Out of 5)\\n1. Was the educational content beneficial?\\n4.3\\n2. Did the textbooks and lecture materials \\n   help you learn?\\n4.5\\n3. Was the training time appropriate?\\n4.5\\n4. The training was composed of content \\n   appropriate to the level of participants \\n   Do you think so?\\n4.5\\n5. Is the purpose of the training and the \\n   curriculum well matched?\\n4.6\\n6. Was the instructor\\'s method appropriate?\\n4.5\\n7. Does the instructor have specialized \\n    skills and knowledge in the field?\\n4.6\\n8. Was the place and environment overall \\n   satisfactory?\\n4.6\\n9. Was the question/answer done properly?\\n4.6\\nTable 10. LLM-based Computer Platform Education \\nSatisfaction Survey Table\\nACKNOWLEDGEMENT\\nThis research was supported by the Ministry of \\nTrade, Industry & Energy(MOTIE), Korea Institute \\nfor Advancement of Technology(KIAT) through \\n“Medical Device Clinical Expert Training Project”\\nREFERENCES\\n[1] Devlin, J., Chang, M. W., Lee, K., & Toutanova, K., \"BERT: \\nPre-training of Deep Bidirectional Transformers for Language \\nUnderstanding,\" arXiv preprint, arXiv:1810.04805, 2019.\\n[2] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., \\nDhariwal, P., ... & Amodei, D., \"Language Models are Few-Shot \\nLearners,\" arXiv preprint, arXiv:2005.14165, 2020.\\n[3] Google Health, \"Using AI to Improve Patient Outcomes in Clinical \\nTrials,\" Google Health Research, https://health.google/research, \\naccessed September 2, 2024.\\n[4] DeepMind, \"AlphaFold: AI for Protein Structure Prediction,\" \\nDeepMind Research, https://www.deepmind.com/research/case-s\\ntudies/alphafold, accessed September 2, 2024.\\n[5] Chen, Q., Allot, A., & Lu, Z., \"Keep up with the latest coronavirus \\nresearch,\" Nature, vol. 579, no. 7798, p. 193, 2020. DOI: 10.1038/\\nd41586-020-00502-w.\\n[6] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, \\nI., \"Language Models are Unsupervised Multitask Learners,\" \\nOpenAI Blog, vol. 1, no. 8, p. 9, 2019.\\n[7] Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. W. H., \\nFeng, M., Ghassemi, M., ... & Mark, R. G., \"MIMIC-III, a freely \\naccessible critical care database,\" Scientific Data, vol. 3, no. 1, \\npp. 1-9, 2016. DOI: 10.1038/sdata.2016.35.\\n[8] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., \\nGomez, A. N., ... & Polosukhin, I., \"Attention is all you need,\" \\nAdvances in Neural Information Processing Systems, pp. \\n5998-6008, 2017. DOI: 10.48550/arXiv.1706.03762.\\n[9] Joulin, A., Grave, E., Bojanowski, P., Mikolov, T., \"Bag of Tricks \\nfor Efficient Text Classification,\" arXiv preprint, arXiv:1607.01\\n759, 2017.\\n[10] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, \\nM., ... & Liu, P. J., \"Exploring the Limits of Transfer Learning \\nwith a Unified Text-to-Text Transformer,\" Journal of Machine \\nLearning Research, vol. 21, no. 140, pp. 1-67, 2020. DOI: 10.\\n48550/arXiv.1910.10683.\\n[11] Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling \\nFeng, Erik Cambria, \"A Survey of Large Language Models for \\nHealthcare: from Data, Technology, and Applications to'),\n",
       " Document(metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 11}, page_content='180   Journal of The Korea Society of Computer and Information \\nAccountability and Ethics,\" Journal of LaTeX Class Files, vol. \\n14, no. 8, pp. 1-8, August 2021.\\n[12] Democratizing Artificial Intelligence Research, Education, and \\nTechnologies, \"Prompting Engineering Guide,\" Prompting Guide, \\nhttps://www.promptingguide.ai.\\n[13] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, \\nMarie-Anne Lachaux, Timothee Lacroix, Baptiste Rozière, \\nNaman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, \\nArmand Joulin, Edouard Grave, Guillaume Lample, \"LLaMA: \\nOpen and Efficient Foundation Language Models,\" Meta AI \\nResearch, 2023. DOI: 10.48550/arXiv.2302.13971.\\n[14] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, \\nBrian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, Denny Zhou, \\n\"Chain-of-Thought Prompting Elicits Reasoning in Large \\nLanguage Models,\" Google Research, Brain Team, 2022.\\n[15] Xie, T., Zhang, X., Tang, Z., Wang, Y., Wang, D., Lin, Z., ... \\n& Huang, T., \"A Survey of Large Language Models for \\nHealthcare: From Data, Technology, and Applications to \\nAccountability and Ethics,\" 2023.\\n[16] He, K., Mao, R., Lin, Q., Ruan, Y., Lan, X., Feng, M., & Cambria, \\nE., \"A Survey of Large Language Models for Healthcare: from \\nData, Technology, and Applications to Accountability and Ethics,\" \\nIEEE Transactions on Neural Networks and Learning Systems, \\n2024.\\n[17] Liu, L., Yang, X., Lei, J., Liu, X., Shen, Y., Zhang, Z., Wei, \\nP., Gu, J., Chu, Z., Qin, Z., & Ren, K., \"A Survey on Medical \\nLarge \\nLanguage \\nModels: \\nTechnology, \\nApplication, \\nTrustworthiness, and Future Directions,\" Journal of LaTeX Class \\nFiles, vol. 14, no. 8, pp. 1, 2024.\\n[18] Yuan, M., Bao, P., Yuan, J., Shen, Y., Chen, Z., Xie, Y., Zhao, \\nJ., Chen, Y., Zhang, L., Shen, L., & Dong, B., \"Large Language \\nModels Illuminate a Progressive Pathway to Artificial Healthcare \\nAssistant: A Review,\" 2024.\\n[19] Mumtaz, U., Ahmed, A., & Mumtaz, S., \"LLMs-Healthcare: \\nCurrent Applications and Challenges of Large Language Models \\nin various Medical Specialties,\" 2024.\\n[20] Mingyu Jin, Qinkai Yu, Dong Shu, Chong Zhang, Lizhou Fan, \\nWenyue Hua, Suiyuan Zhu, Yanda Meng, Zhenting Wang, \\nMengnan Du, Yongfeng Zhang, \"Health-LLM: A Framework for \\nPersonalized Disease Prediction Using Large Language Models \\nand Medical Knowledge,\" arXiv preprint, arXiv:2303.12345, \\n2024.\\nAuthors\\nHyon-Chel \\nJung received the B.S., M.S. \\ndegrees in medical engineering from Konkuk \\nUniversity in 2014 and 2017, respectively, \\nand his Ph.D. in the Department of Health \\nand Safety Convergence from Korea \\nUniversity in 2023. Dr. Jung is currently a research professor \\nat \\nYonsei \\nUniversity\\'s \\nWonju \\nMedical \\nCenter. \\nHe \\nis \\ninterested in medical devices, AI, medicine, and big data.\\nKun-Soo Shin received a bachelor\\'s degree in \\nmedical management from Sangji University \\nin 2022 and is currently studying for a \\nmaster\\'s degree in health management at \\nYonsei University.\\nKun-Soo Shin is currently working for Yonsei University\\'s \\nFuture Medical Industry Cooperation Group. He is interested \\nin medical devices, AI, medicine, and big data.\\nHo-Dong Kim received the B.S. degree in \\nNaval \\nArchitecture \\nfrom \\nSeoul \\nNational \\nUniversity in 1987 and the M.S. degree in \\nManagement \\nInformation \\nEngineering \\nfrom \\nKAIST in 1994.\\nHo-Dong Kim has been working in the IT field since 1987 \\nand joined Solbit Co., Ltd. in 2023. He is currently serving \\nas Executive Vice President and Head of AI at the Corporate \\nResearch Institute of Solbit. His research interests include \\ngenerative artificial intelligence.\\nSung-Bin Park received the B.S., M.S. and \\nPh.D. \\ndegrees \\nin \\nmedicine \\nfrom \\nYonsei \\nUniversity, \\nin \\n1997, \\n1999 \\nand \\n2005, \\nrespectively. Dr. Park is currently a professor \\nof precision medicine at Yonsei University. \\nHe is interested in medical devices, AI, medicine, and big \\ndata.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8eb762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'ezPDF Builder Supreme',\n",
       " 'creator': '',\n",
       " 'creationdate': '2024-12-27T02:09:00+09:00',\n",
       " 'source': '../data/KCI_FI003153549.pdf',\n",
       " 'file_path': '../data/KCI_FI003153549.pdf',\n",
       " 'total_pages': 12,\n",
       " 'format': 'PDF 1.6',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2024-12-27T02:09:00+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20241227020900+09'00'\",\n",
       " 'creationDate': \"D:20241227020900+09'00'\",\n",
       " 'page': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f014ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "splitted_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d34c078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3c6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 임베딩 모델 준비\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"gemini-embedding-001\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb131140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터스토어 생성 및 저장\n",
    "vectorstore = FAISS.from_documents(splitted_documents, embedding_model)\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135b9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 재로딩\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6fd55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리트리버 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c96b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 질의\n",
    "query = \"본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수와 문서 유형별 비율은 어떻게 되나요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171141ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='809aa901-fec5-485a-8880-62ed0e723034', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 4}, page_content='의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\ny 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\ny 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\ny 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\ny 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\ny 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 \\n데이터셋은 \\n의료기기 \\n임상시험에 \\n특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       " Document(id='3ce2274c-1599-43c6-9f36-a3e1c66da7ff', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 5}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement\\nApplication Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation'),\n",
       " Document(id='716bf647-53dd-483a-b4e7-31b775b14592', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 0}, page_content='This study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and'),\n",
       " Document(id='f5c9dbc6-e631-479c-8d26-00b554073c17', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 1}, page_content='170   Journal of The Korea Society of Computer and Information \\n[요   약]\\n본 연구는 대규모 언어 모델(LLM) 기반의 Private LLM을 활용하여 의료기기 임상시험 분야에 \\n적용하여 업무 효율성과 전문성 향상을 탐구한다. Private LLM 시스템은 임상 데이터를 기반으로 \\n정교하고 정확한 답변을 제공하며, 의사결정 지원, 임상 전문가 활동 보조, 새로운 콘텐츠 생성, \\n문제 해결 등 다양한 응용 분야에서 활용 가능성을 보여준다. 연구는 다음 네 가지 주요 단계로 \\n구성된다. 첫째, 의료기기 임상시험에 특화된 데이터를 수집하고 이를 전처리하여 학습 가능한 형\\n식으로 정리한다. 둘째, LLaMA와 같은 오픈소스 LLM 모델을 기반으로 PEFT(LoRA) 및 RAG 기\\n법을 적용하여 특정 임상 도메인에 맞는 맞춤형 Private LLM 질의응답 시스템을 구축한다. 셋째, \\n구축된 시스템을 활용하여 전문가 수준의 질의응답 기능을 실현하고, 임상시험 운영 중 발생하는 \\n복잡한 질문과 문제를 해결한다. 마지막으로, 시스템의 성능을 평가하여 임상시험 운영과 의료기\\n기 개발의 효율성과 신뢰성을 높이기 위한 방향성을 제안한다. 연구 결과, Private LLM 시스템은 \\n기존의 방법론 대비 업무 자동화와 정밀한 의사결정 지원에서 탁월한 성능을 보였다. 특히, 도메\\n인 전문가의 질문에 대한 정확한 답변을 제공하고, 새로운 임상 기준 및 인사이트를 생성할 수 \\n있는 능력은 의료기기 임상시험 운영의 혁신적 도구로 자리잡을 가능성을 보여준다. 이를 통해 \\n정밀 의료, 임상시험 관리 자동화, 그리고 도메인 지식 기반의 질의응답 시스템에서 Private LLM\\n의 실질적 활용 가능성을 확인하였다.\\n▸주제어: 대규모 언어 모델, 생성형 인공지능, 임상시험, 의료기기, 데이터 분석\\nI. Introduction\\n대규모 언어 모델(Large Language Models, LLM)의')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91af7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    '''다음 컨텍스트만 사용해 질문에 답하세요.\n",
    "컨텍스트:{context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b58484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f6375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(query, k=5) # 검색을 외부에서 미리 실행한 후 반환된 결과 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aef5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = chain.invoke({'context': results, 'question': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce70a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수는 **11,954 페이지**입니다.\n",
      "\n",
      "문서 유형별 비율은 다음과 같습니다:\n",
      "*   **규제 문서**: 30% (FDA, EMA, PMDA 가이드라인, GCP 문서 등)\n",
      "*   **교육 자료**: 20% (임상시험 수행자 교육 매뉴얼, 온라인 강의 자료 등)\n",
      "*   **프로토콜 및 보고서**: 25% (임상시험 프로토콜, CSR 템플릿 등)\n",
      "*   **의료기기 특화 문서**: 15% (의료기기 임상시험 계획서, 기술문서 등)\n",
      "*   **기타**: 10% (윤리위원회 관련 문서, 환자 동의서 템플릿 등)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcb139",
   "metadata": {},
   "source": [
    "### LangGraph RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d8d9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb16788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0a6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    return {'context': docs}  # 검색된 문서를 포함한 state를 반환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d02921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain의 hub에 정의된 검증된 RAG 프롬프트 활용\n",
    "# https://smith.langchain.com/hub\n",
    "# rlm: LangChain 팀이 공식적으로 유지보수하는 프롬프트를 의미\n",
    "# rag-prompt: 해당 소유자가 게시한 프롬프트의 이름\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca6a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d96129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문과 검색된 문서를 기반으로 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 검색된 문서를 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 생성된 응답이 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    context = state['context']  # state에서 검색된 문서를 추출합니다.\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    rag_chain = prompt | llm  # RAG 프롬프트와 LLM을 연결하여 체인을 만듭니다.\n",
    "    response = rag_chain.invoke({'question': query, 'context': context})  # 질문과 문맥을 사용하여 응답을 생성합니다.\n",
    "    return {'answer': response}  # 생성된 응답을 포함한 state를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a58138b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x152784c5e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('retrieve', retrieve)\n",
    "graph_builder.add_node('generate', generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26644dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x152784c5e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'retrieve')\n",
    "graph_builder.add_edge('retrieve', 'generate')\n",
    "graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8f68498",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "372c9671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f061bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'query': query}\n",
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f67a62b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수와 문서 유형별 비율은 어떻게 되나요?',\n",
       " 'context': [Document(id='809aa901-fec5-485a-8880-62ed0e723034', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 4}, page_content='의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\ny 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\ny 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\ny 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\ny 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\ny 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 \\n데이터셋은 \\n의료기기 \\n임상시험에 \\n특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       "  Document(id='3ce2274c-1599-43c6-9f36-a3e1c66da7ff', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 5}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement\\nApplication Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation'),\n",
       "  Document(id='716bf647-53dd-483a-b4e7-31b775b14592', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 0}, page_content='This study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and'),\n",
       "  Document(id='f5c9dbc6-e631-479c-8d26-00b554073c17', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 1}, page_content='170   Journal of The Korea Society of Computer and Information \\n[요   약]\\n본 연구는 대규모 언어 모델(LLM) 기반의 Private LLM을 활용하여 의료기기 임상시험 분야에 \\n적용하여 업무 효율성과 전문성 향상을 탐구한다. Private LLM 시스템은 임상 데이터를 기반으로 \\n정교하고 정확한 답변을 제공하며, 의사결정 지원, 임상 전문가 활동 보조, 새로운 콘텐츠 생성, \\n문제 해결 등 다양한 응용 분야에서 활용 가능성을 보여준다. 연구는 다음 네 가지 주요 단계로 \\n구성된다. 첫째, 의료기기 임상시험에 특화된 데이터를 수집하고 이를 전처리하여 학습 가능한 형\\n식으로 정리한다. 둘째, LLaMA와 같은 오픈소스 LLM 모델을 기반으로 PEFT(LoRA) 및 RAG 기\\n법을 적용하여 특정 임상 도메인에 맞는 맞춤형 Private LLM 질의응답 시스템을 구축한다. 셋째, \\n구축된 시스템을 활용하여 전문가 수준의 질의응답 기능을 실현하고, 임상시험 운영 중 발생하는 \\n복잡한 질문과 문제를 해결한다. 마지막으로, 시스템의 성능을 평가하여 임상시험 운영과 의료기\\n기 개발의 효율성과 신뢰성을 높이기 위한 방향성을 제안한다. 연구 결과, Private LLM 시스템은 \\n기존의 방법론 대비 업무 자동화와 정밀한 의사결정 지원에서 탁월한 성능을 보였다. 특히, 도메\\n인 전문가의 질문에 대한 정확한 답변을 제공하고, 새로운 임상 기준 및 인사이트를 생성할 수 \\n있는 능력은 의료기기 임상시험 운영의 혁신적 도구로 자리잡을 가능성을 보여준다. 이를 통해 \\n정밀 의료, 임상시험 관리 자동화, 그리고 도메인 지식 기반의 질의응답 시스템에서 Private LLM\\n의 실질적 활용 가능성을 확인하였다.\\n▸주제어: 대규모 언어 모델, 생성형 인공지능, 임상시험, 의료기기, 데이터 분석\\nI. Introduction\\n대규모 언어 모델(Large Language Models, LLM)의')],\n",
       " 'answer': AIMessage(content='본 연구에서 Private LLM 구축을 위해 총 11,954페이지에 달하는 158개의 문서가 수집되었습니다. 수집된 문서는 규제 문서(30%), 교육 자료(20%), 프로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타(10%)로 구성됩니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--dbd93e9d-e2b3-4ef3-9356-b34fb52fe6b3-0', usage_metadata={'input_tokens': 2707, 'output_tokens': 335, 'total_tokens': 3042, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 256}})}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4104146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 연구에서 Private LLM 구축을 위해 총 11,954페이지에 달하는 158개의 문서가 수집되었습니다. 수집된 문서는 규제 문서(30%), 교육 자료(20%), 프로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타(10%)로 구성됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
