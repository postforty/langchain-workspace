{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c8936b",
   "metadata": {},
   "source": [
    "### ëë§ì‡ê¸° ê²Œì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdec225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6793987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c1e9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--d5ca4798-5f1f-4c44-a83b-79102fd7d539-0', usage_metadata={'input_tokens': 7, 'output_tokens': 103, 'total_tokens': 110, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 93}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a4d1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  íˆìŠ¤í† ë¦¬ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3143d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë‹¹ì‹ ì€ ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê²Œì„ ê·œì¹™ì…ë‹ˆë‹¤. ë‹¹ì‹ ê³¼ user ì˜ ì…ë ¥ì—ì„œ ì•„ë˜ ê·œì¹™ì´ ê¼­ ì§€ì¼œì ¸ì•¼ í•˜ë©°, ì§€í‚¤ì§€ ì•Šì€ ì‚¬ëŒì—ê²Œ íŒ¨ë°°ë¥¼ ì•Œë¦° ë’¤, ëë§ì‡ê¸° ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                1. ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í–ˆì„ ê²½ìš° íŒ¨ë°°í•©ë‹ˆë‹¤.\n",
    "                2. ë‘ìŒë²•ì¹™ì„ í—ˆìš©í•©ë‹ˆë‹¤. (ex. ë¦¬ -> ì´, ë ¥ -> ì—­, ë½ -> ë‚™)\n",
    "                3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì´ì, ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "                4. ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe99489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        # return False\n",
    "        return\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"ìœ„ ì±„íŒ… ë©”ì‹œì§€ëŠ” ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•œ ëŒ€í™”ë‚´ìš©ì…ë‹ˆë‹¤. ì–¸ê¸‰í•œ ë‹¨ì–´ë“¤ë§Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•´ì£¼ì„¸ìš”.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | llm\n",
    "\n",
    "    # chat_history ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í”„ë¡¬í”„íŠ¸ì— ì…ë ¥ & ê²°ê³¼ ì €ì¥\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    # chat_history ì— ì €ì¥ë˜ì–´ìˆë˜ ê¸°ë¡ ì§€ìš°ê¸°\n",
    "    chat_history.clear()\n",
    "\n",
    "    # ìƒì„±ëœ ìƒˆë¡œìš´ ìš”ì•½ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡ ì±„ìš°ê¸°\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    # return True\n",
    "    return\n",
    "\n",
    "chain_with_summarization = (\n",
    "    # RunnablePassthroughëŠ” LCELì—ì„œ ì‚¬ìš©, ì…ë ¥ê°’ì„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚¤ëŠ” ì—­í• \n",
    "    # assign() ë©”ì„œë“œëŠ” ì²´ì¸ì— ë“¤ì–´ì˜¤ëŠ” ë”•ì…”ë„ˆë¦¬ì— ìƒˆë¡œìš´ í‚¤-ê°’ ì¶”ê°€\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages) # ìƒˆë¡œìš´ í‚¤ messages_summarizedì— ê°’(True ë˜ëŠ” False) í• ë‹¹, ì´ ê°’ì€ ì¡°ê±´ë¶€ ìš”ì•½ì— í™œìš© ê°€ëŠ¥\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42832a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë‚™ì—½', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--76a91b8a-9cc7-4ead-bf71-5d96319ac77d-0', usage_metadata={'input_tokens': 169, 'output_tokens': 156, 'total_tokens': 325, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 154}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_summarization.invoke(\n",
    "                {\"input\": \"ë„ì‹œë½\"},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f60387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='ê¸°ì°¨\\nì°¨ë„', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--f4131b26-ecee-4266-8330-af25b550a2da-0', usage_metadata={'input_tokens': 37, 'output_tokens': 311, 'total_tokens': 348, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 306}}),\n",
       " HumanMessage(content='ë„ì‹œë½', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ë‚™ì—½', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--76a91b8a-9cc7-4ead-bf71-5d96319ac77d-0', usage_metadata={'input_tokens': 169, 'output_tokens': 156, 'total_tokens': 325, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 154}})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af642c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AI TURN :  ì§€êµ¬\n",
      "ğŸ¤– AI TURN :  ìŠ¬í””\n",
      "ğŸ¤– AI TURN :  ê·œì¹™ 3ì„ ìœ„ë°˜í•˜ì—¬ íŒ¨ë°°í•˜ì…¨ìŠµë‹ˆë‹¤. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤. ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"ğŸ§‘ YOUR TURN : \")\n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "    response = chain_with_summarization.invoke(\n",
    "                {\"input\": user_input},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )\n",
    "    print(\"ğŸ¤– AI TURN : \", response.content) # AIMessage ê°ì²´ì—ì„œ .content ì¶”ì¶œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
