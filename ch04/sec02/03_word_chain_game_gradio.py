from langchain_core.runnables import RunnablePassthrough
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_google_genai import ChatGoogleGenerativeAI
import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=gemini_api_key)

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  íˆìŠ¤í† ë¦¬ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
chat_history = ChatMessageHistory()

chat_history.messages

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """ë‹¹ì‹ ì€ ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê²Œì„ ê·œì¹™ì…ë‹ˆë‹¤. ë‹¹ì‹ ê³¼ user ì˜ ì…ë ¥ì—ì„œ ì•„ë˜ ê·œì¹™ì´ ê¼­ ì§€ì¼œì ¸ì•¼ í•˜ë©°, ì§€í‚¤ì§€ ì•Šì€ ì‚¬ëŒì—ê²Œ íŒ¨ë°°ë¥¼ ì•Œë¦° ë’¤, ëë§ì‡ê¸° ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
                1. ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í–ˆì„ ê²½ìš° íŒ¨ë°°í•©ë‹ˆë‹¤.
                2. ë‘ìŒë²•ì¹™ì„ í—ˆìš©í•©ë‹ˆë‹¤. (ex. ë¦¬ -> ì´, ë ¥ -> ì—­, ë½ -> ë‚™)
                3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì´ì, ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.
                4. ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            """,
        ),
        ("placeholder", "{chat_history}"),
        ("user", "{input}"),
    ]
)

chain = prompt | llm

chain_with_message_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)

def summarize_messages(chain_input):
    stored_messages = chat_history.messages
    if len(stored_messages) == 0:
        # return False
        return
    summarization_prompt = ChatPromptTemplate.from_messages(
        [
            ("placeholder", "{chat_history}"),
            (
                "user",
                "ìœ„ ì±„íŒ… ë©”ì‹œì§€ëŠ” ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•œ ëŒ€í™”ë‚´ìš©ì…ë‹ˆë‹¤. ì–¸ê¸‰í•œ ë‹¨ì–´ë“¤ë§Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•´ì£¼ì„¸ìš”.",
            ),
        ]
    )
    summarization_chain = summarization_prompt | llm

    # chat_history ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í”„ë¡¬í”„íŠ¸ì— ì…ë ¥ & ê²°ê³¼ ì €ì¥
    summary_message = summarization_chain.invoke({"chat_history": stored_messages})

    # chat_history ì— ì €ì¥ë˜ì–´ìˆë˜ ê¸°ë¡ ì§€ìš°ê¸°
    chat_history.clear()

    # ìƒì„±ëœ ìƒˆë¡œìš´ ìš”ì•½ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡ ì±„ìš°ê¸°
    chat_history.add_message(summary_message)

    # return True
    return

chain_with_summarization = (
    # RunnablePassthroughëŠ” LCELì—ì„œ ì‚¬ìš©, ì…ë ¥ê°’ì„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚¤ëŠ” ì—­í• 
    # assign() ë©”ì„œë“œëŠ” ì²´ì¸ì— ë“¤ì–´ì˜¤ëŠ” ë”•ì…”ë„ˆë¦¬ì— ìƒˆë¡œìš´ í‚¤-ê°’ ì¶”ê°€
    RunnablePassthrough.assign(messages_summarized=summarize_messages) # ìƒˆë¡œìš´ í‚¤ messages_summarizedì— ê°’(True ë˜ëŠ” False) í• ë‹¹, ì´ ê°’ì€ ì¡°ê±´ë¶€ ìš”ì•½ì— í™œìš© ê°€ëŠ¥
    | chain_with_message_history
)

# while True:
#     user_input = input("ğŸ§‘ YOUR TURN : ")
#     if user_input == "ì¢…ë£Œ": break
#     response = chain_with_summarization.invoke(
#                 {"input": user_input},
#                 {"configurable": {"session_id": "unused"}},
#             )
#     print("ğŸ¤– AI TURN : ", response.content) # AIMessage ê°ì²´ì—ì„œ .content ì¶”ì¶œ

import gradio as gr

def word_chain_response(message, history):
    response = chain_with_summarization.invoke(
            {"input": message},
            {"configurable": {"session_id": "unused"}},
        )
    return response.content

demo = gr.ChatInterface(
    word_chain_response, 
    type="messages", 
    autofocus=False,
    title="ğŸ—£ï¸ëë§ì‡ê¸° ê²Œì„",
    description="AIì™€ í•¨ê»˜ ëë§ì‡ê¸° ê²Œì„ì„ í•´ë³´ì„¸ìš”! ë‹¨ì–´ë§Œ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤."
    )

if __name__ == "__main__":
    demo.launch()
