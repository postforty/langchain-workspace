{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330b07f9",
   "metadata": {},
   "source": [
    "### ëë§ì‡ê¸° ê²Œì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f8c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f989cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n",
    "                            google_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "925cc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b890176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë‹¹ì‹ ì€ ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. \n",
    "            ì•„ë˜ëŠ” ê²Œì„ ê·œì¹™ì…ë‹ˆë‹¤.\n",
    "            ë‹¹ì‹ ê³¼ userì˜ ì…ë ¥ì—ì„œ ì•„ë˜ ê·œì¹™ì´ ê¼­ ì§€ì¼œì ¸ì•¼ í•˜ë©°,\n",
    "            ì§€í‚¤ì§€ ì•Šì€ ì‚¬ëŒì—ê²Œ íŒ¨ë°°ë¥¼ ì•Œë¦° ë’¤,\n",
    "            ëë§ì‡ê¸° ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "            1. ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í–ˆì„ ê²½ìš° íŒ¨ë°°í•©ë‹ˆë‹¤.\n",
    "            2. ë‘ìŒë²•ì¸¡ì„ í—ˆìš©í•©ë‹ˆë‹¤. (ex. ë¦¬ -> ì´, ë ¥ -> ì—­, ë½ -> ë‚™)\n",
    "            3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì´ì, ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "            4. ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50e8fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baf8d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"ìœ„ ì±„íŒ… ë©”ì‹œì§€ëŠ” ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•œ ëŒ€í™”ë‚´ìš©ì…ë‹ˆë‹¤. ì–¸ê¸‰í•œ ë‹¨ì–´ë“¤ë§Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•´ì£¼ì„¸ìš”.\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | chat\n",
    "\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    chat_history.clear()\n",
    "\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    print(\"summary_message:\", summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a287257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain_with_summarization.invoke(\n",
    "#         {\"input\": \"ë­ì²´ì¸\"},\n",
    "#         {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "#     ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f538b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤–AI TURN: ì¸ìƒ\n",
      "summary_message: content='ë­ì²´ì¸\\nì¸ìƒ' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--c214d081-074f-49aa-9096-fc72665b9254-0' usage_metadata={'input_tokens': 38, 'output_tokens': 247, 'total_tokens': 285, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 241}}\n",
      "ğŸ¤–AI TURN: ê°ë„\n",
      "summary_message: content='ë­ì²´ì¸\\nì¸ìƒ\\nìƒê°\\nê°ë„' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--b6b05d1b-221a-42a3-b37b-e7409c828c19-0' usage_metadata={'input_tokens': 44, 'output_tokens': 205, 'total_tokens': 249, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 193}}\n",
      "ğŸ¤–AI TURN: ë‚™ì§€\n",
      "summary_message: content='ë­ì²´ì¸\\nì¸ìƒ\\nìƒê°\\nê°ë„\\në„ì‹œë½\\në‚™ì§€' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--6c3e1618-3f70-4862-b59f-da3a643ddfaf-0' usage_metadata={'input_tokens': 50, 'output_tokens': 422, 'total_tokens': 472, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 404}}\n",
      "ğŸ¤–AI TURN: ì‹íƒ\n",
      "summary_message: content='ë­ì²´ì¸, ì¸ìƒ, ìƒê°, ê°ë„, ë„ì‹œë½, ë‚™ì§€, ì§€ì‹, ì‹íƒ' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--c93ca55b-03ca-4716-95cb-677edd912da8-0' usage_metadata={'input_tokens': 56, 'output_tokens': 462, 'total_tokens': 518, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 440}}\n",
      "ğŸ¤–AI TURN: ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ëŠ” ë‹¤ì‹œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì´ íŒ¨ë°°í–ˆìŠµë‹ˆë‹¤. ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"ğŸ‘¨YOUR TURN: \")\n",
    "    \n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "\n",
    "    response = chain_with_summarization.invoke(\n",
    "        {\"input\": user_input},\n",
    "        {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ¤–AI TURN:\", response.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
