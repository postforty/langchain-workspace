{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0419b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 문서 로드\n",
    "file_path = \"../example_data/KCI_FI003153549.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b8b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 분할\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # 최대 길이(1000자 이하)\n",
    "    chunk_overlap=200 # 정확히 200자 중첩\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec521a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/gemini-embedding-001\",\n",
    "        google_api_key=gemini_api_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fab886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [chunk.page_content for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4ca415",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_model.embed_documents(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b0d49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5bbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e8f68",
   "metadata": {},
   "source": [
    "#### FAISS 벡터스토어 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb89a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7921d802",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAISS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vector_store = \u001b[43mFAISS\u001b[49m.from_documents(chunks, embeddings_model) \u001b[38;5;66;03m# 메모리에 저장(in-memory)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'FAISS' is not defined"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.from_documents(chunks, embeddings_model) # 메모리에 저장(in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca200035",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"./faiss_index\") # 영구적으로 디스크에 저장(local disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba16494",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "        \"./faiss_index\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e2901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x224f0309160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064c59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수와 문서 유형별 비율은 어떻게 되나요?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8231207",
   "metadata": {},
   "source": [
    "#### similarity_search() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe204568",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_store.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18de56b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c264a709-b6da-420c-9777-1ca8e1284784', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\n\\x9f 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\n\\x9f 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\n\\x9f 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\n\\x9f 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\n\\x9f 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 데이터셋은 의료기기 임상시험에 특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       " Document(id='aea39792-d397-4296-8e13-9d890c1c7eeb', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement Application Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation'),\n",
       " Document(id='db6f1bbb-cac3-47de-bad2-9b1a09db9ee1', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='This study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4506061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    '''다음 컨텍스트만 사용해 질문에 답하세요.\n",
    "컨텍스트:{context}\n",
    "\n",
    "질문:{question}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0013c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n",
    "                            google_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f39d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='다음 컨텍스트만 사용해 질문에 답하세요.\\n컨텍스트:{context}\\n\\n질문:{question}\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff6ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b23dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b948cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resonse = chain.invoke({\"context\": result, \"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68ae61f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수는 **11,954 페이지**이며, 문서 유형별 비율은 다음과 같습니다:\n",
      "\n",
      "*   **규제 문서:** 30%\n",
      "*   **교육 자료:** 20%\n",
      "*   **프로토콜 및 보고서:** 25%\n",
      "*   **의료기기 특화 문서:** 15%\n",
      "*   **기타:** 10%\n"
     ]
    }
   ],
   "source": [
    "print(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d707049",
   "metadata": {},
   "source": [
    "#### as_retriever() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5668b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f06df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000224F0309160>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3ffe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c264a709-b6da-420c-9777-1ca8e1284784', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\n\\x9f 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\n\\x9f 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\n\\x9f 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\n\\x9f 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\n\\x9f 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 데이터셋은 의료기기 임상시험에 특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       " Document(id='aea39792-d397-4296-8e13-9d890c1c7eeb', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement Application Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation'),\n",
       " Document(id='db6f1bbb-cac3-47de-bad2-9b1a09db9ee1', metadata={'producer': 'ezPDF Builder Supreme', 'creator': 'PyPDF', 'creationdate': '2024-12-27T02:09:00+09:00', 'moddate': '2024-12-27T02:09:00+09:00', 'source': '../example_data/KCI_FI003153549.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='This study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c894ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b448fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(query) # query는 RunnablePassthrough()를 통과하여 question이라는 키의 값이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b85e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수는 **11,954 페이지**입니다.\n",
      "\n",
      "문서 유형별 비율은 다음과 같습니다:\n",
      "*   **규제 문서**: 30%\n",
      "*   **교육 자료**: 20%\n",
      "*   **프로토콜 및 보고서**: 25%\n",
      "*   **의료기기 특화 문서**: 15%\n",
      "*   **기타**: 10%\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
