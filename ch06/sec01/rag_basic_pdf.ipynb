{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87f0b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bfbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 문서 로드\n",
    "loader = PyMuPDFLoader('../data/KCI_FI003153549.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3076fb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1019406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "splitted_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f51265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1705b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# 임베딩 모델 준비\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"gemini-embedding-001\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8265805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 인덱스 faiss_index를 로드합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터스토어가 존재하는 경우에는 덮어쓰기 하지 않고 로드\n",
    "FAISS_INDEX_PATH = \"faiss_index\"\n",
    "\n",
    "if os.path.exists(FAISS_INDEX_PATH):\n",
    "    print(f\"FAISS 인덱스 {FAISS_INDEX_PATH}를 로드합니다.\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        FAISS_INDEX_PATH,\n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "else:\n",
    "    print(f\"FAISS 인덱스 {FAISS_INDEX_PATH}가 없으므로 생성합니다.\")\n",
    "    \n",
    "    # FAISS 벡터스토어 생성 및 저장\n",
    "    vectorstore = FAISS.from_documents(splitted_documents, embedding_model)\n",
    "    vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "    print(f\"FAISS 인덱스를 {FAISS_INDEX_PATH}에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66408551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x29c8a757c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79c593c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2bd8f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000029C8A757C50>, search_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7017a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 질의\n",
    "query = \"본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수와 문서 유형별 비율은 어떻게 되나요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f9b26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1e7c1c04-1d78-418d-a4bc-56556251c239', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 4}, page_content='의료기기 임상시험 분야의 도메인 특성에 맞게 튜닝하\\n기 위해 의료기기 임상시험 전문가로부터 총 158개의 문\\n서(총 11,954 페이지)를 수집하였다. 수집된 문서는 다음\\n과 같이 분류된다:\\ny 규제 문서 (30%): FDA, EMA, PMDA 가이드라인, \\nGCP 문서 등\\ny 교육 자료 (20%): 임상시험 수행자 교육 매뉴얼, 온라\\n인 강의 자료 등\\ny 프로토콜 및 보고서 (25%): 임상시험 프로토콜, CSR \\n(Clinical Study Report) 템플릿 등\\ny 의료기기 특화 문서 (15%): 의료기기 임상시험 계획\\n서, 기술문서 등\\ny 기타 (10%): 윤리위원회 관련 문서, 환자 동의서 템플\\n릿 등\\n1.2 Validity of Collected Data\\n수집된 \\n데이터셋은 \\n의료기기 \\n임상시험에 \\n특화된 \\nPrivate LLM 구축을 위해 도메인 적합성과 다양성, 그리\\n고 응용 가능성 측면에서 높은 타당성을 갖추고 있다. 총 \\n111,954페이지로 구성된 데이터는 의료기기 임상시험의 \\n규제, 프로토콜 설계, 데이터 관리 등 전반적인 지식을 포\\n괄하며, 국제 표준과 실제 임상시험 환경에서 발생할 수 \\n있는 다양한 시나리오를 반영하도록 설계되었다.\\n수집된 데이터는 규제 문서(30%), 교육 자료(20%), 프\\n로토콜 및 보고서(25%), 의료기기 특화 문서(15%), 기타'),\n",
       " Document(id='dceb63f7-acbe-4236-9f08-f12794145130', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 5}, page_content='174   Journal of The Korea Society of Computer and Information \\n문서(10%)로 구성되며, 각 분류는 도메인 전문가의 검토를 \\n통해 정확성과 신뢰성을 확보하였다. 특히, 주요 규제 기\\n관(FDA, EMA, PMDA) 가이드라인, GCP 문서, 환자 동의\\n서 템플릿 등은 모델이 국제 표준에 기반하여 학습할 수 \\n있도록 하였고, 교육 자료와 프로토콜은 실질적인 임상시\\n험 수행과 데이터 관리 작업에서 발생할 수 있는 질문들에 \\n대응할 수 있는 기초를 제공한다.\\n이 데이터셋은 다양한 문서 형식(PDF, DOCX, PPTX \\n등)과 내용적 깊이를 갖추고 있어 모델 학습의 맥락 이해\\n와 응답 생성 능력을 강화하며, 특정 주제에 편중되지 않\\n도록 균형 있게 설계되었다. 또한, 추후 멀티모달 데이터\\n(예: 의료 이미지, 통계 그래프 등)와의 통합 가능성을 염\\n두에 두어 데이터셋의 확장성을 보장하였다.\\n데이터 증강(Data Augmentation)은 고려되었으나, 전\\n문가의 검토 결과 현재 수집된 데이터셋이 충분한 다양성\\n과 문맥적 깊이를 갖추고 있다고 판단되어 구축 단계에서\\n는 적용되지 않았다. 이는 모델 학습의 적합성과 신뢰성을 \\n유지하면서도 도메인 특화된 LLM 구축에 필요한 데이터 \\n품질을 확보하는 데 기여하였다.\\n1.3 Data preprocessing \\n수집된 문서는 PDF, 워드, 한글, 파워포인트, 엑셀 등 \\n다양한 형식과 서로 다른 레이아웃을 가지고 있어, 일관된 \\n자연어 처리 작업을 위해 전처리가 필요하다. 이를 위해 \\nTable 6와 같은 데이터 전처리 과정을 거쳤다.\\nClassification \\nElement\\nApplication Basis\\nText Extraction \\nand Conversion\\nOrganizes Text, Image, and Table \\nelements from PDF, PPT, Word, \\nExcel, and HWP files\\nSensitive \\nInformation'),\n",
       " Document(id='a702dfc7-ef9f-41e7-ab0d-5172cb05f7fb', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 0}, page_content='This study explores the improvement of work efficiency and expertise by applying Private LLM \\nbased on Large Language Model (LLM) to the field of clinical trials in medical devices. The Private \\nLLM system provides sophisticated and accurate answers based on clinical data and shows its potential \\nfor use in various applications such as decision support, clinical expert activity assistance, new content \\ngeneration, and problem solving. The study consists of the following four main steps. First, data \\nspecific to clinical trials of medical devices are collected, preprocessed, and organized into a learnable \\nformat. Second, based on open-source LLM models such as LaMA, PEFT (LoRA) and RAG techniques \\nare applied to build a customized private LLM Q&A system for a specific clinical domain. Third, it \\nrealizes expert-level Q&A function by utilizing the established system and solves complex questions and'),\n",
       " Document(id='0d4dda96-fe06-4184-a9d3-d037750d695c', metadata={'producer': 'ezPDF Builder Supreme', 'creator': '', 'creationdate': '2024-12-27T02:09:00+09:00', 'source': '../data/KCI_FI003153549.pdf', 'file_path': '../data/KCI_FI003153549.pdf', 'total_pages': 12, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-12-27T02:09:00+09:00', 'trapped': '', 'modDate': \"D:20241227020900+09'00'\", 'creationDate': \"D:20241227020900+09'00'\", 'page': 1}, page_content='170   Journal of The Korea Society of Computer and Information \\n[요   약]\\n본 연구는 대규모 언어 모델(LLM) 기반의 Private LLM을 활용하여 의료기기 임상시험 분야에 \\n적용하여 업무 효율성과 전문성 향상을 탐구한다. Private LLM 시스템은 임상 데이터를 기반으로 \\n정교하고 정확한 답변을 제공하며, 의사결정 지원, 임상 전문가 활동 보조, 새로운 콘텐츠 생성, \\n문제 해결 등 다양한 응용 분야에서 활용 가능성을 보여준다. 연구는 다음 네 가지 주요 단계로 \\n구성된다. 첫째, 의료기기 임상시험에 특화된 데이터를 수집하고 이를 전처리하여 학습 가능한 형\\n식으로 정리한다. 둘째, LLaMA와 같은 오픈소스 LLM 모델을 기반으로 PEFT(LoRA) 및 RAG 기\\n법을 적용하여 특정 임상 도메인에 맞는 맞춤형 Private LLM 질의응답 시스템을 구축한다. 셋째, \\n구축된 시스템을 활용하여 전문가 수준의 질의응답 기능을 실현하고, 임상시험 운영 중 발생하는 \\n복잡한 질문과 문제를 해결한다. 마지막으로, 시스템의 성능을 평가하여 임상시험 운영과 의료기\\n기 개발의 효율성과 신뢰성을 높이기 위한 방향성을 제안한다. 연구 결과, Private LLM 시스템은 \\n기존의 방법론 대비 업무 자동화와 정밀한 의사결정 지원에서 탁월한 성능을 보였다. 특히, 도메\\n인 전문가의 질문에 대한 정확한 답변을 제공하고, 새로운 임상 기준 및 인사이트를 생성할 수 \\n있는 능력은 의료기기 임상시험 운영의 혁신적 도구로 자리잡을 가능성을 보여준다. 이를 통해 \\n정밀 의료, 임상시험 관리 자동화, 그리고 도메인 지식 기반의 질의응답 시스템에서 Private LLM\\n의 실질적 활용 가능성을 확인하였다.\\n▸주제어: 대규모 언어 모델, 생성형 인공지능, 임상시험, 의료기기, 데이터 분석\\nI. Introduction\\n대규모 언어 모델(Large Language Models, LLM)의')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "323210a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    '''다음 컨텍스트만 사용해 질문에 답하세요.\n",
    "컨텍스트: {context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad7831",
   "metadata": {},
   "source": [
    "### 지식 기반 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b4112",
   "metadata": {},
   "source": [
    "#### 1. 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b12d2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.invoke(query) # 벡터DB 검색 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd381c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수는 **11,954 페이지**입니다.\\n\\n문서 유형별 비율은 다음과 같습니다:\\n*   **규제 문서**: 30%\\n*   **교육 자료**: 20%\\n*   **프로토콜 및 보고서**: 25%\\n*   **의료기기 특화 문서**: 15%\\n*   **기타**: 10%'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'context': results, 'question': query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c710d",
   "metadata": {},
   "source": [
    "#### 2. retriever, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77cbaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9055ac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'본 연구에서 Private LLM 구축을 위해 수집한 문서의 총 페이지 수는 **111,954페이지**이며, 문서 유형별 비율은 다음과 같습니다.\\n\\n*   **규제 문서**: 30% (FDA, EMA, PMDA 가이드라인, GCP 문서 등)\\n*   **교육 자료**: 20% (임상시험 수행자 교육 매뉴얼, 온라인 강의 자료 등)\\n*   **프로토콜 및 보고서**: 25% (임상시험 프로토콜, CSR 템플릿 등)\\n*   **의료기기 특화 문서**: 15% (의료기기 임상시험 계획서, 기술문서 등)\\n*   **기타**: 10% (윤리위원회 관련 문서, 환자 동의서 템플릿 등)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
